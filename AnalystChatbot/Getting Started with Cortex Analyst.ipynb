{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "iiaz4lqnourxldijvlwi",
   "authorId": "8198607234849",
   "authorName": "FH_LAB0",
   "authorEmail": "",
   "sessionId": "c0f5af0d-cc1c-4c5b-a10b-39076cd970c1",
   "lastEditTime": 1740719778513
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2035c0ea-58c5-4370-8c5c-6e393585aaf6",
   "metadata": {
    "name": "cell4",
    "collapsed": false
   },
   "source": "[**Quickstart: Getting Started with Cortex Analyst**](https://quickstarts.snowflake.com/guide/getting_started_with_cortex_analyst/index.html?index=..%2F..index#0)\n\n\nCortex Analyst is a fully managed service in Cortex AI that provides a conversational interface to interact with structured data in Snowflake. It streamlines the development of intuitive, self-service analytics applications for business users, while providing industry-leading accuracy. To deliver high text-to-SQL accuracy, Cortex Analyst uses an agentic AI setup powered by state-of-the-art LLMs. \n\nAvailable as a convenient REST API, Cortex Analyst can seamlessly integrate into any application. This empowers developers to customize how and where business users interact with results, while still benefiting from Snowflake's integrated security and governance features, including role-based access controls (RBAC), to protect valuable data.\n"
  },
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "cell1",
    "collapsed": false
   },
   "source": "# Import python packages\nimport streamlit as st\nimport pandas as pd\n\n# We can also use Snowpark for our analyses!\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "8845da85-f032-44ff-89db-62da0b2c0452",
   "metadata": {
    "name": "cell10",
    "collapsed": false
   },
   "source": "2. Set up the Sample Financial Data \n"
  },
  {
   "cell_type": "code",
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "language": "sql",
    "name": "cell2",
    "collapsed": false
   },
   "source": "/*--\nSET CONTEXT\nUpdate the Database name\n--*/\n\nUSE DATABASE FH_CORTEX_ANALYST_DEMO0;\nUSE SCHEMA revenue_timeseries;\n\n-- Create stage for raw data\nCREATE OR REPLACE STAGE raw_data DIRECTORY = (ENABLE = TRUE);\n\n/*--\nâ€¢ Fact and Dimension Table Creation\n--*/\n\n-- Fact table: daily_revenue\nCREATE OR REPLACE TABLE revenue_timeseries.daily_revenue (\n    date DATE,\n    revenue FLOAT,\n    cogs FLOAT,\n    forecasted_revenue FLOAT,\n    product_id INT,\n    region_id INT\n);\n\n-- Dimension table: product_dim\nCREATE OR REPLACE TABLE revenue_timeseries.product_dim (\n    product_id INT,\n    product_line VARCHAR(16777216)\n);\n\n-- Dimension table: region_dim\nCREATE OR REPLACE TABLE revenue_timeseries.region_dim (\n    region_id INT,\n    sales_region VARCHAR(16777216),\n    state VARCHAR(16777216)\n);",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "208e4ac8-edbe-466d-830a-c9c845fd660c",
   "metadata": {
    "name": "cell5",
    "collapsed": false
   },
   "source": "3. Ingest the Revenue Data and Semantic Model YAML\n\nDownload the three data files and one YAML file included in the Git Repo: daily_revenue.csv, region.csv, product.csv, revenue_timeseries.yaml\n\n**!!! EDIT revenue_timeseries.yaml to reference your Database name !!!**\n\nUpload all four files to the RAW_DATA Stage\n\n"
  },
  {
   "cell_type": "code",
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "language": "sql",
    "name": "cell3",
    "collapsed": false
   },
   "source": "/*--\nâ€¢ looad data into tables\n--*/\n\nCOPY INTO REVENUE_TIMESERIES.DAILY_REVENUE\nFROM @raw_data\nFILES = ('daily_revenue.csv')\nFILE_FORMAT = (\n    TYPE=CSV,\n    SKIP_HEADER=1,\n    FIELD_DELIMITER=',',\n    TRIM_SPACE=FALSE,\n    FIELD_OPTIONALLY_ENCLOSED_BY=NONE,\n    REPLACE_INVALID_CHARACTERS=TRUE,\n    DATE_FORMAT=AUTO,\n    TIME_FORMAT=AUTO,\n    TIMESTAMP_FORMAT=AUTO\n    EMPTY_FIELD_AS_NULL = FALSE\n    error_on_column_count_mismatch=false\n)\n\nON_ERROR=CONTINUE\nFORCE = TRUE ;\n\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "59b4f753-fbed-4e2f-85ab-dbf1ab2b4e3a",
   "metadata": {
    "language": "sql",
    "name": "cell7",
    "collapsed": false
   },
   "outputs": [],
   "source": "\nCOPY INTO REVENUE_TIMESERIES.PRODUCT_DIM\nFROM @raw_data\nFILES = ('product.csv')\nFILE_FORMAT = (\n    TYPE=CSV,\n    SKIP_HEADER=1,\n    FIELD_DELIMITER=',',\n    TRIM_SPACE=FALSE,\n    FIELD_OPTIONALLY_ENCLOSED_BY=NONE,\n    REPLACE_INVALID_CHARACTERS=TRUE,\n    DATE_FORMAT=AUTO,\n    TIME_FORMAT=AUTO,\n    TIMESTAMP_FORMAT=AUTO\n    EMPTY_FIELD_AS_NULL = FALSE\n    error_on_column_count_mismatch=false\n)\n\nON_ERROR=CONTINUE\nFORCE = TRUE ;\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2eab301f-77ce-49e0-8a5e-95e447021448",
   "metadata": {
    "language": "sql",
    "name": "cell6",
    "collapsed": false
   },
   "outputs": [],
   "source": "COPY INTO REVENUE_TIMESERIES.REGION_DIM\nFROM @raw_data\nFILES = ('region.csv')\nFILE_FORMAT = (\n    TYPE=CSV,\n    SKIP_HEADER=1,\n    FIELD_DELIMITER=',',\n    TRIM_SPACE=FALSE,\n    FIELD_OPTIONALLY_ENCLOSED_BY=NONE,\n    REPLACE_INVALID_CHARACTERS=TRUE,\n    DATE_FORMAT=AUTO,\n    TIME_FORMAT=AUTO,\n    TIMESTAMP_FORMAT=AUTO\n    EMPTY_FIELD_AS_NULL = FALSE\n    error_on_column_count_mismatch=false\n)\n\nON_ERROR=CONTINUE\nFORCE = TRUE ;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1593067b-0b49-4e03-8de5-989db4e7f249",
   "metadata": {
    "name": "cell9",
    "collapsed": false
   },
   "source": "4. Integrate Cortex Search\n\nNow, you will integrate Cortex Search as a way to improve literal string searches to help Cortex Analyst generate more accurate SQL queries. Writing the correct SQL query to answer a question sometimes requires knowing exact literal values to filter on. Since those values can't always be extracted directly from the question, a search of some kind may be needed.\n\nGo back to your Snowflake SQL worksheet and run the following cortex_search_create.sql code to load data into the tables:\n"
  },
  {
   "cell_type": "code",
   "id": "762400cd-11ee-4829-974f-3047dfe9cdb7",
   "metadata": {
    "language": "sql",
    "name": "cell11"
   },
   "outputs": [],
   "source": "show warehouses;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1d63194b-c35f-4981-8975-c6ed84a9b301",
   "metadata": {
    "language": "sql",
    "name": "cell8",
    "collapsed": false
   },
   "outputs": [],
   "source": "/*--\nintegrate Cortex Search as a way to improve literal string searches to help Cortex Analyst generate more accurate SQL queries\n\nUpdate Warehouse name\n--*/\n\nCREATE OR REPLACE CORTEX SEARCH SERVICE product_line_search_service\n  ON product_dimension\n  WAREHOUSE = FH_CORTEX_ANALYST_WH0\n  TARGET_LAG = '1 hour'\n  AS (\n      SELECT DISTINCT product_line AS product_dimension FROM product_dim\n  );",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e9d87d1a-fc17-4c0a-82c6-75425bb94ac0",
   "metadata": {
    "name": "cell13",
    "collapsed": false
   },
   "source": "5. Create a Streamlit Conversational App\n\nUpdate the Code below and copy to create a streamlit in snowflake app\n\nUpdate Database on line 21"
  },
  {
   "cell_type": "code",
   "id": "aa349f5f-48de-482b-acc7-9e90513bc874",
   "metadata": {
    "language": "python",
    "name": "cell12",
    "collapsed": false
   },
   "outputs": [],
   "source": "\"\"\"\nCortex Analyst App\n====================\nThis app allows users to interact with their data using natural language.\n\"\"\"\n\nimport json  # To handle JSON data\nimport time\nfrom typing import Dict, List, Optional, Tuple\n\nimport _snowflake  # For interacting with Snowflake-specific APIs\nimport pandas as pd\nimport streamlit as st  # Streamlit library for building the web app\nfrom snowflake.snowpark.context import (\n    get_active_session,\n)  # To interact with Snowflake sessions\nfrom snowflake.snowpark.exceptions import SnowparkSQLException\n\n# List of available semantic model paths in the format: <DATABASE>.<SCHEMA>.<STAGE>/<FILE-NAME>\n# Each path points to a YAML file defining a semantic model\nAVAILABLE_SEMANTIC_MODELS_PATHS = [\n    \"FH_CORTEX_ANALYST_DEMO0.REVENUE_TIMESERIES.RAW_DATA/revenue_timeseries.yaml\"\n]\nAPI_ENDPOINT = \"/api/v2/cortex/analyst/message\"\nAPI_TIMEOUT = 50000  # in milliseconds\n\n# Initialize a Snowpark session for executing queries\nsession = get_active_session()\n\n\ndef main():\n    # Initialize session state\n    if \"messages\" not in st.session_state:\n        reset_session_state()\n    show_header_and_sidebar()\n    if len(st.session_state.messages) == 0:\n        process_user_input(\"What questions can I ask?\")\n    display_conversation()\n    handle_user_inputs()\n    handle_error_notifications()\n\n\ndef reset_session_state():\n    \"\"\"Reset important session state elements.\"\"\"\n    st.session_state.messages = []  # List to store conversation messages\n    st.session_state.active_suggestion = None  # Currently selected suggestion\n\n\ndef show_header_and_sidebar():\n    \"\"\"Display the header and sidebar of the app.\"\"\"\n    # Set the title and introductory text of the app\n    st.title(\"Cortex Analyst\")\n    st.markdown(\n        \"Welcome to Cortex Analyst! Type your questions below to interact with your data. \"\n    )\n\n    # Sidebar with a reset button\n    with st.sidebar:\n        st.selectbox(\n            \"Selected semantic model:\",\n            AVAILABLE_SEMANTIC_MODELS_PATHS,\n            format_func=lambda s: s.split(\"/\")[-1],\n            key=\"selected_semantic_model_path\",\n            on_change=reset_session_state,\n        )\n        st.divider()\n        # Center this button\n        _, btn_container, _ = st.columns([2, 6, 2])\n        if btn_container.button(\"Clear Chat History\", use_container_width=True):\n            reset_session_state()\n\n\ndef handle_user_inputs():\n    \"\"\"Handle user inputs from the chat interface.\"\"\"\n    # Handle chat input\n    user_input = st.chat_input(\"What is your question?\")\n    if user_input:\n        process_user_input(user_input)\n    # Handle suggested question click\n    elif st.session_state.active_suggestion is not None:\n        suggestion = st.session_state.active_suggestion\n        st.session_state.active_suggestion = None\n        process_user_input(suggestion)\n\n\ndef handle_error_notifications():\n    if st.session_state.get(\"fire_API_error_notify\"):\n        st.toast(\"An API error has occured!\", icon=\"ðŸš¨\")\n        st.session_state[\"fire_API_error_notify\"] = False\n\n\ndef process_user_input(prompt: str):\n    \"\"\"\n    Process user input and update the conversation history.\n\n    Args:\n        prompt (str): The user's input.\n    \"\"\"\n\n    # Create a new message, append to history and display imidiately\n    new_user_message = {\n        \"role\": \"user\",\n        \"content\": [{\"type\": \"text\", \"text\": prompt}],\n    }\n    st.session_state.messages.append(new_user_message)\n    with st.chat_message(\"user\"):\n        user_msg_index = len(st.session_state.messages) - 1\n        display_message(new_user_message[\"content\"], user_msg_index)\n\n    # Show progress indicator inside analyst chat message while waiting for response\n    with st.chat_message(\"analyst\"):\n        with st.spinner(\"Waiting for Analyst's response...\"):\n            time.sleep(1)\n            response, error_msg = get_analyst_response(st.session_state.messages)\n            if error_msg is None:\n                analyst_message = {\n                    \"role\": \"analyst\",\n                    \"content\": response[\"message\"][\"content\"],\n                    \"request_id\": response[\"request_id\"],\n                }\n            else:\n                analyst_message = {\n                    \"role\": \"analyst\",\n                    \"content\": [{\"type\": \"text\", \"text\": error_msg}],\n                    \"request_id\": response[\"request_id\"],\n                }\n                st.session_state[\"fire_API_error_notify\"] = True\n            st.session_state.messages.append(analyst_message)\n            st.rerun()\n\n\ndef get_analyst_response(messages: List[Dict]) -> Tuple[Dict, Optional[str]]:\n    \"\"\"\n    Send chat history to the Cortex Analyst API and return the response.\n\n    Args:\n        messages (List[Dict]): The conversation history.\n\n    Returns:\n        Optional[Dict]: The response from the Cortex Analyst API.\n    \"\"\"\n    # Prepare the request body with the user's prompt\n    request_body = {\n        \"messages\": messages,\n        \"semantic_model_file\": f\"@{st.session_state.selected_semantic_model_path}\",\n    }\n\n    # Send a POST request to the Cortex Analyst API endpoint\n    # Adjusted to use positional arguments as per the API's requirement\n    resp = _snowflake.send_snow_api_request(\n        \"POST\",  # method\n        API_ENDPOINT,  # path\n        {},  # headers\n        {},  # params\n        request_body,  # body\n        None,  # request_guid\n        API_TIMEOUT,  # timeout in milliseconds\n    )\n\n    # Content is a string with serialized JSON object\n    parsed_content = json.loads(resp[\"content\"])\n\n    # Check if the response is successful\n    if resp[\"status\"] < 400:\n        # Return the content of the response as a JSON object\n        return parsed_content, None\n    else:\n        # Craft readable error message\n        error_msg = f\"\"\"\nðŸš¨ An Analyst API error has occurred ðŸš¨\n\n* response code: `{resp['status']}`\n* request-id: `{parsed_content['request_id']}`\n* error code: `{parsed_content['error_code']}`\n\nMessage:\n```\n{parsed_content['message']}\n```\n        \"\"\"\n        return parsed_content, error_msg\n\n\ndef display_conversation():\n    \"\"\"\n    Display the conversation history between the user and the assistant.\n    \"\"\"\n    for idx, message in enumerate(st.session_state.messages):\n        role = message[\"role\"]\n        content = message[\"content\"]\n        with st.chat_message(role):\n            display_message(content, idx)\n\n\ndef display_message(content: List[Dict[str, str]], message_index: int):\n    \"\"\"\n    Display a single message content.\n\n    Args:\n        content (List[Dict[str, str]]): The message content.\n        message_index (int): The index of the message.\n    \"\"\"\n    for item in content:\n        if item[\"type\"] == \"text\":\n            st.markdown(item[\"text\"])\n        elif item[\"type\"] == \"suggestions\":\n            # Display suggestions as buttons\n            for suggestion_index, suggestion in enumerate(item[\"suggestions\"]):\n                if st.button(\n                    suggestion, key=f\"suggestion_{message_index}_{suggestion_index}\"\n                ):\n                    st.session_state.active_suggestion = suggestion\n        elif item[\"type\"] == \"sql\":\n            # Display the SQL query and results\n            display_sql_query(item[\"statement\"], message_index)\n        else:\n            # Handle other content types if necessary\n            pass\n\n\n@st.cache_data(show_spinner=False)\ndef get_query_exec_result(query: str) -> Tuple[Optional[pd.DataFrame], Optional[str]]:\n    \"\"\"\n    Execute the SQL query and convert the results to a pandas DataFrame.\n\n    Args:\n        query (str): The SQL query.\n\n    Returns:\n        Tuple[Optional[pd.DataFrame], Optional[str]]: The query results and the error message.\n    \"\"\"\n    global session\n    try:\n        df = session.sql(query).to_pandas()\n        return df, None\n    except SnowparkSQLException as e:\n        return None, str(e)\n\n\ndef display_sql_query(sql: str, message_index: int):\n    \"\"\"\n    Executes the SQL query and displays the results in form of data frame and charts.\n\n    Args:\n        sql (str): The SQL query.\n        message_index (int): The index of the message.\n    \"\"\"\n\n    # Display the SQL query\n    with st.expander(\"SQL Query\", expanded=False):\n        st.code(sql, language=\"sql\")\n\n    # Display the results of the SQL query\n    with st.expander(\"Results\", expanded=True):\n        with st.spinner(\"Running SQL...\"):\n            df, err_msg = get_query_exec_result(sql)\n            if df is None:\n                st.error(f\"Could not execute generated SQL query. Error: {err_msg}\")\n                return\n\n            if df.empty:\n                st.write(\"Query returned no data\")\n                return\n\n            # Show query results in two tabs\n            data_tab, chart_tab = st.tabs([\"Data ðŸ“„\", \"Chart ðŸ“ˆ \"])\n            with data_tab:\n                st.dataframe(df, use_container_width=True)\n\n            with chart_tab:\n                display_charts_tab(df, message_index)\n\n\ndef display_charts_tab(df: pd.DataFrame, message_index: int) -> None:\n    \"\"\"\n    Display the charts tab.\n\n    Args:\n        df (pd.DataFrame): The query results.\n        message_index (int): The index of the message.\n    \"\"\"\n    # There should be at least 2 columns to draw charts\n    if len(df.columns) >= 2:\n        all_cols_set = set(df.columns)\n        col1, col2 = st.columns(2)\n        x_col = col1.selectbox(\n            \"X axis\", all_cols_set, key=f\"x_col_select_{message_index}\"\n        )\n        y_col = col2.selectbox(\n            \"Y axis\",\n            all_cols_set.difference({x_col}),\n            key=f\"y_col_select_{message_index}\",\n        )\n        chart_type = st.selectbox(\n            \"Select chart type\",\n            options=[\"Line Chart ðŸ“ˆ\", \"Bar Chart ðŸ“Š\"],\n            key=f\"chart_type_{message_index}\",\n        )\n        if chart_type == \"Line Chart ðŸ“ˆ\":\n            st.line_chart(df.set_index(x_col)[y_col])\n        elif chart_type == \"Bar Chart ðŸ“Š\":\n            st.bar_chart(df.set_index(x_col)[y_col])\n    else:\n        st.write(\"At least 2 columns are required\")\n\n\nif __name__ == \"__main__\":\n    main()",
   "execution_count": null
  }
 ]
}